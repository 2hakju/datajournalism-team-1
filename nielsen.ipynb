{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url_list 만들기\n",
    "\n",
    "from datetime import timedelta, date\n",
    "\n",
    "def daterange(date1, date2):\n",
    "    for n in range(int ((date2 - date1).days)+1):\n",
    "        yield date1 + timedelta(n)\n",
    "start_dt = date(2017, 1, 1)\n",
    "end_dt = date(2017, 1, 1)\n",
    "\n",
    "url_list = []\n",
    "for dt in daterange(start_dt, end_dt):\n",
    "    dtdt = dt.strftime(\"%Y%m%d\")\n",
    "    url_list.append(\"https://www.nielsenkorea.co.kr/tv_terrestrial_day.asp?menu=Tit_1&sub_menu=1_1&area=00&begin_date={}\".format(dtdt))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#크롤링해서 JSON에 저장(문제는 중복된 프로그램명은 낮은 시청률을 반영한다는 것, 보수적 접근)\n",
    "\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "\n",
    "pn_list = []\n",
    "pnss = OrderedDict()\n",
    "for base_url in url_list:\n",
    "    \n",
    "    with urllib.request.urlopen(base_url) as url:\n",
    "    \n",
    "        doc = url.read()\n",
    "        soup = BeautifulSoup(doc, \"html.parser\")\n",
    "        names = soup.find_all(\"td\", class_=\"tb_txt\")\n",
    "        percents10 = soup.find_all(\"td\", class_=\"percent\")\n",
    "        percents20 = soup.find_all(\"td\", class_=\"percent_g\")\n",
    "    \n",
    "        name_list = []\n",
    "        percent_list = []\n",
    "        pnss[\"날짜\"] = base_url[-8:]\n",
    "        for name in names[0:20]:\n",
    "            name_list.append(name.text.strip())\n",
    "        for percent10 in percents10[0:10]:\n",
    "            percent_list.append(percent10.text.strip())\n",
    "        for percent20 in percents20[0:10]:\n",
    "            percent_list.append(percent20.text.strip())\n",
    "        for i in range(0,20):\n",
    "            pnss[name_list[i]] = percent_list[i]\n",
    "        \n",
    "\n",
    "    pn_list.append(pnss)\n",
    "    \n",
    "with open('rating2017.json', 'w', encoding=\"utf-8\") as make_file:\n",
    "    json.dump(pn_list, make_file, ensure_ascii=False, indent=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.nielsenkorea.co.kr/tv_terrestrial_day.asp?menu=Tit_1&sub_menu=1_1&area=00&begin_date=20170101']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
